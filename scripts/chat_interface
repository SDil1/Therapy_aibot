import gradio as gr

# Function to generate response
def chat_with_ai(user_input):
    # Tokenize user input
    inputs = tokenizer("User: " + user_input, return_tensors="pt").to(model.device)
    
    # Generate output
    outputs = model.generate(
        **inputs,
        max_new_tokens=150,
        do_sample=True,
        temperature=0.7,
        top_p=0.9
    )
    
    # Decode output
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # Remove repeated "User:" if model echoes input
    response = response.replace("User:", "").strip()
    return response

# Gradio interface
iface = gr.Interface(
    fn=chat_with_ai,
    inputs="text",
    outputs="text",
    title="Therapist AI",
    description="Talk to your AI therapist. Share your feelings and get supportive responses."
)

# Launch the interface
iface.launch()
